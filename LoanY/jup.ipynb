{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import toml\n",
    "import panel as pn  # GUI\n",
    "\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Load configuration from config.toml\n",
    "config = toml.load('/Users/cameronhightower/Documents/Socratic_CS_Tutor/.streamlit/config.toml')\n",
    "\n",
    "# Set the OpenAI API key from the config file\n",
    "openai.api_key = config['openai']['api_key']\n",
    "\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_from_messages(messages, model=llm_model, temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, styles={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "file = '/Users/cameronhightower/Documents/LoFi/docs/conventional_loans.txt'\n",
    "loader = TextLoader(file_path=file)\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "# Using the vector store index creator \n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])\n",
    "\n",
    "query = \"Acting as a loan officer, ask a couple of questions to determine if a buyer is eligible for a conventional loan\"\n",
    "\n",
    "num_responses = 1\n",
    "responses = []\n",
    "import langchain\n",
    "langchain.debug = True\n",
    "for i in range(num_responses):\n",
    "    responses.append(index.query(query))\n",
    "for response in responses:\n",
    "    display(Markdown(response))\n",
    "langchain.debug = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "\n",
    "@tool\n",
    "def va_pamphlet(text: str) -> str:\n",
    "    \"\"\"Queries the VA Pamphlet \\\n",
    "    Used for potential buyers who are military service members, veterans, or eligible family members. \\\n",
    "    The input should be an empty string. \\\n",
    "    This function will always return a follow up question. \\\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(\"/Users/cameronhightower/Documents/LoFi/docs/va_pamphlet.pdf\")\n",
    "    index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader])\n",
    "    return index.query(str)\n",
    "\n",
    "\n",
    "@tool\n",
    "def general_overview(text: str) -> str:\n",
    "    \"\"\"Queries the general overview document \\\n",
    "    Used for potential buyers who are military service members, veterans, or eligible family members. \\\n",
    "    The input should be an empty string. \\\n",
    "    This function will always return a follow up question. \\\n",
    "    \"\"\"\n",
    "    loader = TextLoader(file_path=file)\n",
    "    index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader])\n",
    "    return index.query(str)\n",
    "\n",
    "\n",
    "\n",
    "agent= initialize_agent(\n",
    "    [va_pamphlet], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import panel as pn  # GUI\n",
    "import langchain\n",
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "\n",
    "\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "\n",
    "You are a loan officer trying to find the best loan options for a prospective home buyer.\\\n",
    "When the user greets you, say \"Hello, I'm here to find the best home buying options for you.  Are you ready to answer some questions?\" \\\n",
    "Ask them a series of questions one by one to determine the best 4 loan options for them.\\\n",
    "\n",
    "\"\"\"} ] \n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text hereâ€¦')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=600),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
